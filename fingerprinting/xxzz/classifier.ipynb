{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d58b6a9-b75a-4d51-ba07-038131ac8597",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay, roc_auc_score, precision_recall_curve, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b56122-3d41-42e9-9abc-d37002933d52",
   "metadata": {},
   "source": [
    "### Added Features:\n",
    "- `readout_match`: Binary feature; 1 if the logical readout (L) matches the expected readout, otherwise 0.\n",
    "- `index_flip`: Eight columns (index_flip_0 to index_flip_7), representing the number of bit flips for each index between the three rounds.\n",
    "- `agreement`: Proportion of bits that agree across all three rounds for each row.\n",
    "- `flip_errs`: Count of the number of errors (1s) in the last four bits (Z3, Z2, Z1, Z0) of each round, where these bits should always be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e04a2c2-4d34-449b-b51e-292ecf093f60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# File paths for the JSON files\n",
    "json_files = [\n",
    "    'data/json/qubit1Z_d3_a1_results.json',\n",
    "    'data/json/qubit1Z_d3_a2_results.json',\n",
    "    'data/json/qubit1Z_d3_b1_results.json'\n",
    "]\n",
    "\n",
    "# Output file path for the concatenated results\n",
    "output_file = 'data/json/qubit1Z_d3_combined_results.json'\n",
    "\n",
    "# Function to load a JSON file\n",
    "def load_json_data(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file_path} not found.\")\n",
    "        return {}\n",
    "\n",
    "# Main script to concatenate JSON files\n",
    "def combine_data(json_files, output_file) : \n",
    "    # Create an empty dictionary to store the concatenated data\n",
    "    combined_data = {}\n",
    "\n",
    "    # Loop over each JSON file and update the combined data\n",
    "    for file_path in json_files:\n",
    "        json_data = load_json_data(file_path)\n",
    "        \n",
    "        # Merge the json_data with combined_data\n",
    "        for backend, data in json_data.items():\n",
    "            if backend in combined_data:\n",
    "                combined_data[backend].update(data)  # Update existing backend data\n",
    "            else:\n",
    "                combined_data[backend] = data  # Add new backend data\n",
    "    \n",
    "    # Save the combined data to a new JSON file\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(combined_data, f, indent=4)\n",
    "\n",
    "    print(f\"Data has been successfully concatenated into {output_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edcad6bc-4785-4126-a23d-d2b206dd5e20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def json_to_expanded_df(json_file, d = 5, num_rounds = 3):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    def process_data(data):\n",
    "        rows = []\n",
    "        for backend, results in data.items():\n",
    "            for key, count in results.items():\n",
    "                split_data = key.split()  # Split based on space\n",
    "                readout = int(split_data[0])  # L value (Z readout)\n",
    "                bitstrings = split_data[1:]  # Remaining are the rounds\n",
    "\n",
    "                # Flatten the bitstrings into individual bits\n",
    "                expanded_bits = [int(bit) for bitstring in bitstrings for bit in bitstring]\n",
    "                \n",
    "                # Append backend, expanded bits, readout, and count\n",
    "                rows.append([backend] + expanded_bits + [readout, count])\n",
    "\n",
    "        return rows\n",
    "\n",
    "    # Dynamically generate column names based on the bitstring length\n",
    "    measure_bits = (d*d)-1  # 24 bits per round of d=5\n",
    "\n",
    "    columns = ['backend']\n",
    "    for r in range(num_rounds):\n",
    "        for q in range(measure_bits):\n",
    "            columns.append(f'bit_{q}_round_{r}')\n",
    "\n",
    "    columns += ['z_readout', 'count']\n",
    "    return pd.DataFrame(process_data(data), columns=columns)\n",
    "\n",
    "def calculate_index_flip(row, measure_bits):\n",
    "    \"\"\"Calculate the number of flips for each bit between rounds.\"\"\"\n",
    "    flips = []\n",
    "    \n",
    "    # Iterate through the measure_bits bits \n",
    "    for i in range(measure_bits):\n",
    "        # Check flips between round_0, round_1, and round_2\n",
    "        bit_r0 = row[f'bit_{i}_round_0']\n",
    "        bit_r1 = row[f'bit_{i}_round_1']\n",
    "        bit_r2 = row[f'bit_{i}_round_2']\n",
    "        \n",
    "        # Count the flips between consecutive rounds\n",
    "        flip_count = (bit_r0 != bit_r1) + (bit_r1 != bit_r2)\n",
    "        flips.append(flip_count)\n",
    "    \n",
    "    return flips\n",
    "\n",
    "def calculate_agreement(row, measure_bits):\n",
    "    \"\"\"Calculate the agreement between rounds for each bit.\"\"\"\n",
    "    agreement_count = 0\n",
    "\n",
    "    # Iterate through the measure_bits bits and check if they agree across rounds\n",
    "    for i in range(measure_bits):\n",
    "        bit_r0 = row[f'bit_{i}_round_0']\n",
    "        bit_r1 = row[f'bit_{i}_round_1']\n",
    "        bit_r2 = row[f'bit_{i}_round_2']\n",
    "        \n",
    "        # Check if the bits are the same in all rounds\n",
    "        if bit_r0 == bit_r1 == bit_r2:\n",
    "            agreement_count += 1\n",
    "\n",
    "    return agreement_count / measure_bits  # Proportion of agreement\n",
    "\n",
    "def calculate_flip_errs(row, measure_bits):\n",
    "    \"\"\"\n",
    "    Calculate the number of errors (1s) in the last measure_bits/2 bits of each round.\n",
    "\n",
    "    Parameters:\n",
    "    row: The row containing the bits data.\n",
    "    measure_bits: The total number of measurement bits. \n",
    "                  The function will check the last measure_bits/2 bits for errors.\n",
    "    \"\"\"\n",
    "    flip_errs = 0\n",
    "    half_measure_bits = measure_bits // 2  # Calculate half of measure_bits\n",
    "\n",
    "    # Iterate through the last half_measure_bits bits for each round\n",
    "    for i in range(measure_bits - half_measure_bits, measure_bits):\n",
    "        flip_errs += row[f'bit_{i}_round_0']\n",
    "        flip_errs += row[f'bit_{i}_round_1']\n",
    "        flip_errs += row[f'bit_{i}_round_2']\n",
    "\n",
    "    return flip_errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "554f4046-162c-4884-951e-37a6280a8d11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_backend_classifier(df, expected_readout=0, d=5):\n",
    "    measure_bits = (d*d)-1\n",
    "    \n",
    "    df = df[df['backend'] != 'ibm_sherbrooke_a2'].copy()  # Ensure we're working on a copy\n",
    "    df = df[df['backend'] != 'ibm_brisbane_a2'].copy()\n",
    "    df = df[df['backend'] != 'ibm_kyiv_a2'].copy()\n",
    "    \n",
    "    # readout_match (1 if z_readout matches expected_readout, else 0)\n",
    "    df['readout_match'] = (df['z_readout'] == expected_readout).astype(int)\n",
    "    \n",
    "    # index_flip (how many times each bit flips between rounds)\n",
    "    index_flip_cols = [f'index_flip_{i}' for i in range(measure_bits)]\n",
    "    \n",
    "    # index_flip_cols (flips between rounds)\n",
    "    df[index_flip_cols] = df.apply(lambda row: calculate_index_flip(row, measure_bits), axis=1, result_type='expand')\n",
    "\n",
    "    # agreement (proportion of bits that agree across rounds)\n",
    "    df['agreement'] = df.apply(lambda row: calculate_agreement(row, measure_bits), axis=1)\n",
    "\n",
    "    # flip_errs (count of errors in the last measure_bits/2 bits of each round)\n",
    "    df['flip_errs'] = df.apply(lambda row: calculate_flip_errs(row, measure_bits), axis=1)\n",
    "    \n",
    "    # Select features for training (excluding backend and count)\n",
    "    X = df.drop(columns=['backend', 'count'])\n",
    "    y = df['backend']  # Target\n",
    "    \n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Create and train the RandomForestClassifier\n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions and evaluation\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Output accuracy and classification report\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return clf, df, y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "588feeea-88b0-4395-8161-561a4f325e54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_svm_classifier(df, target_backend, expected_readout=0, d=5, adjust_threshold=False, threshold=0.5):\n",
    "    measure_bits = (d*d)-1\n",
    "\n",
    "    df = df[df['backend'] != 'ibm_sherbrooke_a2'].copy()  # Ensure we're working on a copy\n",
    "    df = df[df['backend'] != 'ibm_brisbane_a2'].copy()\n",
    "    df = df[df['backend'] != 'ibm_kyiv_a2'].copy()\n",
    "\n",
    "    # readout_match (1 if z_readout matches expected_readout, else 0)\n",
    "    df['readout_match'] = (df['z_readout'] == expected_readout).astype(int)\n",
    "\n",
    "    # index_flip (how many times each bit flips between rounds)\n",
    "    index_flip_cols = [f'index_flip_{i}' for i in range(measure_bits)]\n",
    "    df[index_flip_cols] = df.apply(lambda row: calculate_index_flip(row, measure_bits), axis=1, result_type='expand')\n",
    "\n",
    "    # agreement (proportion of bits that agree across rounds)\n",
    "    df['agreement'] = df.apply(lambda row: calculate_agreement(row, measure_bits), axis=1)\n",
    "\n",
    "    # flip_errs (count of errors in the last measure_bits/2 bits of each round)\n",
    "    df['flip_errs'] = df.apply(lambda row: calculate_flip_errs(row, measure_bits), axis=1)\n",
    "\n",
    "    # Convert the 'backend' column to binary (1 for target_backend, 0 for others)\n",
    "    df['binary_backend'] = (df['backend'] == target_backend).astype(int)\n",
    "\n",
    "    # Check class distribution before resampling\n",
    "    print(\"Class distribution before resampling:\")\n",
    "    print(df['binary_backend'].value_counts())\n",
    "\n",
    "    # Select features for training (excluding original backend and count columns)\n",
    "    X = df.drop(columns=['backend', 'count', 'binary_backend'])\n",
    "    y = df['binary_backend']  # Binary target variable\n",
    "\n",
    "    # Apply SMOTE to oversample the minority class (1)\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "    # Check class distribution after resampling\n",
    "    print(\"Class distribution after resampling:\")\n",
    "    print(y_resampled.value_counts())\n",
    "\n",
    "    # Split data using stratified sampling to maintain class balance\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, stratify=y_resampled, random_state=42)\n",
    "\n",
    "    # Ensure there are two classes present in training data\n",
    "    print(\"Training set class distribution:\", y_train.value_counts())\n",
    "    print(\"Test set class distribution:\", y_test.value_counts())\n",
    "\n",
    "    if len(y_train.unique()) == 1:\n",
    "        raise ValueError(\"Training set only contains one class. Check the distribution or increase dataset size.\")\n",
    "\n",
    "    # Create and train the SVM with class_weight='balanced'\n",
    "    svm = SVC(kernel='rbf', class_weight='balanced', probability=True, random_state=42)\n",
    "    print('Created SVM...')\n",
    "    svm.fit(X_train, y_train)\n",
    "    print('\\tFit SVM')\n",
    "\n",
    "    # Get probability predictions\n",
    "    y_proba = svm.predict_proba(X_test)[:, 1]  # Probability for the positive class\n",
    "\n",
    "    # Apply custom threshold if needed\n",
    "    if adjust_threshold:\n",
    "        y_pred = (y_proba >= threshold).astype(int)\n",
    "    else:\n",
    "        y_pred = svm.predict(X_test)\n",
    "\n",
    "    print('Got y pred')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "    # Print evaluation metrics\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Plot Precision-Recall Curve\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "    plt.plot(recall, precision, marker='.', label='Precision-Recall Curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.show()\n",
    "\n",
    "    return svm, df, y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdbfb06d-db24-4cfd-872b-584c322145cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_svm_classifier(df, target_backend, expected_readout=0, d=5, adjust_threshold=False, threshold=0.5):\n",
    "    measure_bits = (d*d)-1\n",
    "\n",
    "    df = df[df['backend'] != 'ibm_sherbrooke_a2'].copy()  # Ensure we're working on a copy\n",
    "    df = df[df['backend'] != 'ibm_brisbane_a2'].copy()\n",
    "    df = df[df['backend'] != 'ibm_kyiv_a2'].copy()\n",
    "\n",
    "    # readout_match (1 if z_readout matches expected_readout, else 0)\n",
    "    df['readout_match'] = (df['z_readout'] == expected_readout).astype(int)\n",
    "\n",
    "    # index_flip (how many times each bit flips between rounds)\n",
    "    index_flip_cols = [f'index_flip_{i}' for i in range(measure_bits)]\n",
    "    df[index_flip_cols] = df.apply(lambda row: calculate_index_flip(row, measure_bits), axis=1, result_type='expand')\n",
    "\n",
    "    # agreement (proportion of bits that agree across rounds)\n",
    "    df['agreement'] = df.apply(lambda row: calculate_agreement(row, measure_bits), axis=1)\n",
    "\n",
    "    # flip_errs (count of errors in the last measure_bits/2 bits of each round)\n",
    "    df['flip_errs'] = df.apply(lambda row: calculate_flip_errs(row, measure_bits), axis=1)\n",
    "\n",
    "    # Convert the 'backend' column to binary (1 for target_backend, 0 for others)\n",
    "    df['binary_backend'] = (df['backend'] == target_backend).astype(int)\n",
    "\n",
    "    # Check class distribution before splitting\n",
    "    print(\"Class distribution before splitting:\")\n",
    "    print(df['binary_backend'].value_counts())\n",
    "\n",
    "    # Select features for training (excluding original backend and count columns)\n",
    "    X = df.drop(columns=['backend', 'count', 'binary_backend'])\n",
    "    y = df['binary_backend']  # Binary target variable\n",
    "\n",
    "    # Split data using stratified sampling to maintain class balance\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "    # Check class distribution in the training and testing sets\n",
    "    print(\"Training set class distribution before resampling:\", y_train.value_counts())\n",
    "    print(\"Test set class distribution:\", y_test.value_counts())\n",
    "\n",
    "    # Apply SMOTE to oversample the minority class only on the training data\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Check class distribution after resampling\n",
    "    print(\"Training set class distribution after resampling:\")\n",
    "    print(y_train_resampled.value_counts())\n",
    "\n",
    "    # Ensure there are two classes present in the resampled training data\n",
    "    if len(y_train_resampled.unique()) == 1:\n",
    "        raise ValueError(\"Training set only contains one class. Check the distribution or increase dataset size.\")\n",
    "\n",
    "    # Create and train the SVM with class_weight='balanced'\n",
    "    svm = SVC(kernel='rbf', class_weight='balanced', probability=True, random_state=42)\n",
    "    print('Created SVM...')\n",
    "    svm.fit(X_train_resampled, y_train_resampled)\n",
    "    print('\\tFit SVM')\n",
    "\n",
    "    # Get probability predictions on the test set (real data, no resampling)\n",
    "    y_proba = svm.predict_proba(X_test)[:, 1]  # Probability for the positive class\n",
    "\n",
    "    # Apply custom threshold if needed\n",
    "    if adjust_threshold:\n",
    "        y_pred = (y_proba >= threshold).astype(int)\n",
    "    else:\n",
    "        y_pred = svm.predict(X_test)\n",
    "\n",
    "    print('Got y pred')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "    # Print evaluation metrics\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Plot Precision-Recall Curve\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "    plt.plot(recall, precision, marker='.', label='Precision-Recall Curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.show()\n",
    "\n",
    "    return svm, df, y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81b1435a-b7cd-4369-9a50-d72bef276776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, classification_report, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def build_mlp_classifier(df, target_backend, expected_readout=0, d=5, adjust_threshold=False, threshold=0.5):\n",
    "    measure_bits = (d * d) - 1\n",
    "\n",
    "    df = df[df['backend'] != 'ibm_sherbrooke_a2'].copy()  # Ensure we're working on a copy\n",
    "    df = df[df['backend'] != 'ibm_brisbane_a2'].copy()\n",
    "    df = df[df['backend'] != 'ibm_kyiv_a2'].copy()\n",
    "\n",
    "    # readout_match (1 if z_readout matches expected_readout, else 0)\n",
    "    df['readout_match'] = (df['z_readout'] == expected_readout).astype(int)\n",
    "\n",
    "    # index_flip (how many times each bit flips between rounds)\n",
    "    index_flip_cols = [f'index_flip_{i}' for i in range(measure_bits)]\n",
    "    df[index_flip_cols] = df.apply(lambda row: calculate_index_flip(row, measure_bits), axis=1, result_type='expand')\n",
    "\n",
    "    # agreement (proportion of bits that agree across rounds)\n",
    "    df['agreement'] = df.apply(lambda row: calculate_agreement(row, measure_bits), axis=1)\n",
    "\n",
    "    # flip_errs (count of errors in the last measure_bits/2 bits of each round)\n",
    "    df['flip_errs'] = df.apply(lambda row: calculate_flip_errs(row, measure_bits), axis=1)\n",
    "\n",
    "    # Convert the 'backend' column to binary (1 for target_backend, 0 for others)\n",
    "    df['binary_backend'] = (df['backend'] == target_backend).astype(int)\n",
    "\n",
    "    # Check class distribution before splitting\n",
    "    print(\"Class distribution before splitting:\")\n",
    "    print(df['binary_backend'].value_counts())\n",
    "\n",
    "    # Select features for training (excluding original backend and count columns)\n",
    "    X = df.drop(columns=['backend', 'count', 'binary_backend'])\n",
    "    y = df['binary_backend']  # Binary target variable\n",
    "\n",
    "    # Split data using stratified sampling to maintain class balance\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "    # Check class distribution in the training and testing sets\n",
    "    print(\"Training set class distribution before resampling:\", y_train.value_counts())\n",
    "    print(\"Test set class distribution:\", y_test.value_counts())\n",
    "\n",
    "    # Apply SMOTE to oversample the minority class only on the training data\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Check class distribution after resampling\n",
    "    print(\"Training set class distribution after resampling:\")\n",
    "    print(y_train_resampled.value_counts())\n",
    "\n",
    "    # Ensure there are two classes present in the resampled training data\n",
    "    if len(y_train_resampled.unique()) == 1:\n",
    "        raise ValueError(\"Training set only contains one class. Check the distribution or increase dataset size.\")\n",
    "\n",
    "    # Create and train the MLP Classifier\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)\n",
    "    print('Created MLP...')\n",
    "    mlp.fit(X_train_resampled, y_train_resampled)\n",
    "    print('\\tFit MLP')\n",
    "\n",
    "    # Get probability predictions on the test set (real data, no resampling)\n",
    "    y_proba = mlp.predict_proba(X_test)[:, 1]  # Probability for the positive class\n",
    "\n",
    "    # # Apply custom threshold if needed\n",
    "    # if adjust_threshold:\n",
    "    #     y_pred = (y_proba >= threshold).astype(int)\n",
    "    # else:\n",
    "    #     y_pred = mlp.predict(X_test)\n",
    "\n",
    "    print('Got y pred')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    # Calculate FPR and FNR\n",
    "    fpr = fp / (fp + tn)  # False Positive Rate\n",
    "    fnr = fn / (fn + tp)  # False Negative Rate\n",
    "\n",
    "    # Print evaluation metrics\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "    print(f\"False Positive Rate (FPR): {fpr:.2f}\")\n",
    "    print(f\"False Negative Rate (FNR): {fnr:.2f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Plot Precision-Recall Curve\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "    plt.plot(recall, precision, marker='.', label='Precision-Recall Curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.show()\n",
    "\n",
    "    return mlp, df, y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ce131a4-6cad-49f4-81c3-bfc9af73d1b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_backend_results(df, backend, suffix, d=5):\n",
    "    target_backend = f'{backend}{suffix}'\n",
    "    print(f\"Classifying for backend: {target_backend}\")\n",
    "    clf, df, y_test, y_pred = build_mlp_classifier(df, target_backend=target_backend, expected_readout=0, d=d)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy for {target_backend}: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    return clf, y_test, y_pred\n",
    "\n",
    "def plot_confusion_matrices(results, filename):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        cm = confusion_matrix(result['y_test'], result['y_pred'])\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap='magma', ax=plt.gca(), colorbar=False)\n",
    "        plt.title(result['backend'])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "def get_results_all_backends(backends = ['ibm_brisbane', 'ibm_sherbrooke', 'ibm_kyiv'], suffixes = ['_a1', '_b1']):\n",
    "    results = []\n",
    "\n",
    "    json_file = 'data/json/qubit1Z_d5_combined_results.json'\n",
    "    df = json_to_expanded_df(json_file, d=5)\n",
    "\n",
    "    # Loop through backends and suffixes\n",
    "    for backend in backends:\n",
    "        for suffix in suffixes:\n",
    "            mlp, df, y_test, y_pred = get_backend_results(df, backend, suffix, d=5)\n",
    "            results.append({\n",
    "                'backend': f'{backend}{suffix}',\n",
    "                'mlp': mlp,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred\n",
    "            })\n",
    "            \n",
    "    plot_confusion_matrices(results, 'qubit1Z_d5_binary_smote.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa5508ae-6a1a-4ec7-ba5a-4e25b4603fd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying for backend: ibm_brisbane_a1\n",
      "Class distribution before splitting:\n",
      "binary_backend\n",
      "0    30000\n",
      "1     5000\n",
      "Name: count, dtype: int64\n",
      "Training set class distribution before resampling: binary_backend\n",
      "0    21000\n",
      "1     3500\n",
      "Name: count, dtype: int64\n",
      "Test set class distribution: binary_backend\n",
      "0    9000\n",
      "1    1500\n",
      "Name: count, dtype: int64\n",
      "Training set class distribution after resampling:\n",
      "binary_backend\n",
      "0    21000\n",
      "1    21000\n",
      "Name: count, dtype: int64\n",
      "Created MLP...\n",
      "\tFit MLP\n",
      "Got y pred\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_results_all_backends()\n",
      "Cell \u001b[0;32mIn[11], line 33\u001b[0m, in \u001b[0;36mget_results_all_backends\u001b[0;34m(backends, suffixes)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m backend \u001b[38;5;129;01min\u001b[39;00m backends:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m suffix \u001b[38;5;129;01min\u001b[39;00m suffixes:\n\u001b[0;32m---> 33\u001b[0m         mlp, df, y_test, y_pred \u001b[38;5;241m=\u001b[39m get_backend_results(df, backend, suffix, d\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     34\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     35\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackend\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msuffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     36\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmlp\u001b[39m\u001b[38;5;124m'\u001b[39m: mlp,\n\u001b[1;32m     37\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_test\u001b[39m\u001b[38;5;124m'\u001b[39m: y_test,\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m'\u001b[39m: y_pred\n\u001b[1;32m     39\u001b[0m         })\n\u001b[1;32m     41\u001b[0m plot_confusion_matrices(results, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqubit1Z_d5_binary_smote.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m, in \u001b[0;36mget_backend_results\u001b[0;34m(df, backend, suffix, d)\u001b[0m\n\u001b[1;32m      2\u001b[0m target_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msuffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassifying for backend: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_backend\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m clf, df, y_test, y_pred \u001b[38;5;241m=\u001b[39m build_mlp_classifier(df, target_backend\u001b[38;5;241m=\u001b[39mtarget_backend, expected_readout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, d\u001b[38;5;241m=\u001b[39md)\n\u001b[1;32m      5\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_backend\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 73\u001b[0m, in \u001b[0;36mbuild_mlp_classifier\u001b[0;34m(df, target_backend, expected_readout, d, adjust_threshold, threshold)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# # Apply custom threshold if needed\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# if adjust_threshold:\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m#     y_pred = (y_proba >= threshold).astype(int)\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m#     y_pred = mlp.predict(X_test)\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGot y pred\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[1;32m     74\u001b[0m roc_auc \u001b[38;5;241m=\u001b[39m roc_auc_score(y_test, y_proba)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Calculate confusion matrix\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "get_results_all_backends()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f09d61b-71ed-4224-9954-9e39bcf00f27",
   "metadata": {},
   "source": [
    "## d=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa69623-ddef-46cf-9f15-d406386c666a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# qubit1Z_d3_state.pkl : qubit1Z_d3_{backend}_transpiled.qpy (at time of creation)\n",
    "json_file = 'data/json/qubit1Z_d3_results.json'\n",
    "df = json_to_expanded_df(json_file, d=3)\n",
    "clf, updated_df, y_test, y_pred = build_backend_classifier(df, d=3)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap='magma', normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c027f4e5-25f2-4675-98ab-0d183ca70539",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# qubit1Z_d3_state.pkl : qubit1Z_d3_{backend}_transpiled.qpy (1 week later)\n",
    "json_file = 'data/json/qubit1Z_d3_2_results.json'\n",
    "df = json_to_expanded_df(json_file, d=3)\n",
    "clf, updated_df, y_test, y_pred = build_backend_classifier(df, d=3)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap='magma', normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680c6a42-5869-4b69-b463-b9dafefa579a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# qubit1Z_d3_state.pkl : qubit1Z_d3_{backend}_transpiled.qpy (1 week later)\n",
    "json_file = 'data/json/qubit1Z_d3_b_results.json'\n",
    "df = json_to_expanded_df(json_file, d=3)\n",
    "clf, updated_df, y_test, y_pred = build_backend_classifier(df, d=3)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap='magma', normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4231e5-f277-4361-9d13-46f70953bc3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_file = 'data/json/qubit1Z_d3_combined_results.json'\n",
    "df = json_to_expanded_df(json_file, d=3)\n",
    "clf, updated_df, y_test, y_pred = build_backend_classifier(df, d=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea8ce19-372d-4268-882c-5ecd753077aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap='magma', normalize='true')\n",
    "plt.xticks(rotation=90)\n",
    "plt.savefig('qubit1Z_d3_combined_matrix_diffmaps.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a837a79c-a451-477e-947e-8ca3297a24f6",
   "metadata": {},
   "source": [
    "## d=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35227fb-3b1c-4b59-8dc2-b9e0dd6d0e0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# qubit1Z_d5_state.pkl : qubit1Z_d5_{backend}_transpiled.qpy (at time of creation)\n",
    "json_file = 'data/json/qubit1Z_d5_results.json'\n",
    "df = json_to_expanded_df(json_file, d=5)\n",
    "clf, updated_df, y_test, y_pred = build_backend_classifier(df, d=5)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap='magma', normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a33824-3e40-42b4-ad95-3034a2c203cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# qubit1Z_d5_{backend}_transpiled.qpy (approx 1 week after its creation)\n",
    "json_file = 'data/json/qubit1Z_d5_2_results.json'\n",
    "df = json_to_expanded_df(json_file, d=5)\n",
    "clf, updated_df, y_test, y_pred = build_backend_classifier(df, d=5)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap='magma', normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480abfa8-f062-4265-9cd2-0970a298f7a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# qubit1Z_d5_{backend}_transpiled.qpy (approx 1 week after its creation)\n",
    "json_file = 'data/json/qubit1Z_d5_b_results.json'\n",
    "df = json_to_expanded_df(json_file, d=5)\n",
    "clf, updated_df, y_test, y_pred = build_backend_classifier(df, d=5)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap='magma', normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca16e4b-c30d-49af-96b5-7531b9b578ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_file = 'data/json/qubit1Z_d5_combined_results.json'\n",
    "df = json_to_expanded_df(json_file, d=5)\n",
    "clf, updated_df, y_test, y_pred = build_backend_classifier(df, d=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2e2702-2ed5-40c9-8643-05cf55b3a80b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap='magma', normalize='true')\n",
    "plt.xticks(rotation=90)\n",
    "plt.savefig('qubit1Z_d5_combined_matrix_diffmaps.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393a6945-3b9d-4a54-bbe4-7fc7917be18b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_file = 'data/json/qubit1Z_d5_combined_results.json'\n",
    "df = json_to_expanded_df(json_file, d=5)\n",
    "#clf, df, y_test, y_pred = build_binary_backend_classifier(df, expected_readout=0, d=5, target_backend='ibm_brisbane_a1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234d95a6-8a8f-4b63-91c2-c3b7c968a3fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# switch to mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dcc4b3-4c24-4048-960f-7b1eeb8dee3b",
   "metadata": {},
   "source": [
    "- increase # of mappings to classify\n",
    "- classify based on \"older\" transpilations / qpys\n",
    "- change to binary classification\n",
    "- mappings would only matter for qPuf, train one classifier per mapping\n",
    "\n",
    "- rerun saved transpilations from d=5 tomorrow, next week\n",
    "- implement arbitrary mapping?\n",
    "- generate confusion matrix across machines and mappings\n",
    "- gernerate a new classifier per mapping => you expect to know which mapping you're working with\n",
    "    - pull the classifier that you generated for that backend & mapping\n",
    "    - ex: have brisbane mapping a, everything is labeled as brisbane_a or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe368c5-837e-42b8-a11a-328694d6669a",
   "metadata": {},
   "source": [
    "```python\n",
    "for backend in backends:\n",
    "    for mapping_label in [\"a\", \"b\", \"c\"]:\n",
    "        random_layout = np.random.permutation(backend.num_qubits)[\n",
    "            : qc.num_qubits\n",
    "        ]\n",
    "        qc_transpiled = transpile(qc, backend, initial_layout=random_layout)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b0bbd7-5b50-401e-b906-7fa9211ee461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
